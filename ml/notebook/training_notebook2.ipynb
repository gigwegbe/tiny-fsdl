{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. \n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 23:02:46.544839: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFliteNamingAndVersion = \"testing\"   # Used for tflite Filename\n",
    "Training_Percentage = 0.2              # 0.0 = Use all Images for Training\n",
    "Epochs = 200\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 15x25 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8279, 25, 15, 3)\n",
      "(8279, 10)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='../data/raw_images/labelled_bmp_data_equal_combined_final'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.bmp')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for file in files:\n",
    "    base = os.path.basename(file)\n",
    "    target = base[0:1]\n",
    "    category = int(target)\n",
    "    test_image = Image.open(file)\n",
    "    test_image = np.array(test_image, dtype=\"int8\")\n",
    "    x_data.append(test_image)\n",
    "    y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 10)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8279"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6623"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 20, 3)\n",
    "* Number of output layers: 10\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(25,15,3)),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 25, 15, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 8, 16)         4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,130\n",
      "Trainable params: 9,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(lr=1e-4), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.4212 - accuracy: 0.8680 - val_loss: 0.4103 - val_accuracy: 0.8792\n",
      "Epoch 2/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.4113 - accuracy: 0.8738 - val_loss: 0.3980 - val_accuracy: 0.8835\n",
      "Epoch 3/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.4014 - accuracy: 0.8746 - val_loss: 0.3856 - val_accuracy: 0.8786\n",
      "Epoch 4/200\n",
      "130/130 [==============================] - 4s 35ms/step - loss: 0.3762 - accuracy: 0.8850 - val_loss: 0.3887 - val_accuracy: 0.8865\n",
      "Epoch 5/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.3789 - accuracy: 0.8826 - val_loss: 0.3519 - val_accuracy: 0.8998\n",
      "Epoch 6/200\n",
      "130/130 [==============================] - 4s 35ms/step - loss: 0.3717 - accuracy: 0.8902 - val_loss: 0.3643 - val_accuracy: 0.8955\n",
      "Epoch 7/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.3577 - accuracy: 0.8888 - val_loss: 0.3740 - val_accuracy: 0.8925\n",
      "Epoch 8/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.3522 - accuracy: 0.8968 - val_loss: 0.3265 - val_accuracy: 0.9070\n",
      "Epoch 9/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.3312 - accuracy: 0.9011 - val_loss: 0.3347 - val_accuracy: 0.9046\n",
      "Epoch 10/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.3325 - accuracy: 0.8996 - val_loss: 0.3237 - val_accuracy: 0.9106\n",
      "Epoch 11/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.3201 - accuracy: 0.9035 - val_loss: 0.2920 - val_accuracy: 0.9118\n",
      "Epoch 12/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.3129 - accuracy: 0.9069 - val_loss: 0.2844 - val_accuracy: 0.9203\n",
      "Epoch 13/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.3125 - accuracy: 0.9124 - val_loss: 0.2793 - val_accuracy: 0.9203\n",
      "Epoch 14/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.2995 - accuracy: 0.9113 - val_loss: 0.2900 - val_accuracy: 0.9167\n",
      "Epoch 15/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.3019 - accuracy: 0.9153 - val_loss: 0.2860 - val_accuracy: 0.9221\n",
      "Epoch 16/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2843 - accuracy: 0.9196 - val_loss: 0.2925 - val_accuracy: 0.9197\n",
      "Epoch 17/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2659 - accuracy: 0.9235 - val_loss: 0.2580 - val_accuracy: 0.9269\n",
      "Epoch 18/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.2734 - accuracy: 0.9229 - val_loss: 0.2605 - val_accuracy: 0.9197\n",
      "Epoch 19/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2697 - accuracy: 0.9238 - val_loss: 0.2755 - val_accuracy: 0.9167\n",
      "Epoch 20/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2592 - accuracy: 0.9272 - val_loss: 0.2475 - val_accuracy: 0.9324\n",
      "Epoch 21/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2551 - accuracy: 0.9276 - val_loss: 0.2570 - val_accuracy: 0.9300\n",
      "Epoch 22/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2502 - accuracy: 0.9289 - val_loss: 0.2346 - val_accuracy: 0.9336\n",
      "Epoch 23/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2423 - accuracy: 0.9302 - val_loss: 0.2496 - val_accuracy: 0.9281\n",
      "Epoch 24/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2398 - accuracy: 0.9333 - val_loss: 0.2457 - val_accuracy: 0.9239\n",
      "Epoch 25/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2283 - accuracy: 0.9367 - val_loss: 0.2058 - val_accuracy: 0.9378\n",
      "Epoch 26/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2304 - accuracy: 0.9401 - val_loss: 0.2168 - val_accuracy: 0.9396\n",
      "Epoch 27/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2159 - accuracy: 0.9405 - val_loss: 0.2150 - val_accuracy: 0.9384\n",
      "Epoch 28/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2138 - accuracy: 0.9412 - val_loss: 0.2178 - val_accuracy: 0.9457\n",
      "Epoch 29/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2110 - accuracy: 0.9397 - val_loss: 0.1903 - val_accuracy: 0.9481\n",
      "Epoch 30/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.2072 - accuracy: 0.9453 - val_loss: 0.2084 - val_accuracy: 0.9438\n",
      "Epoch 31/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.2054 - accuracy: 0.9427 - val_loss: 0.1965 - val_accuracy: 0.9450\n",
      "Epoch 32/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1967 - accuracy: 0.9446 - val_loss: 0.2045 - val_accuracy: 0.9475\n",
      "Epoch 33/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1920 - accuracy: 0.9469 - val_loss: 0.1743 - val_accuracy: 0.9589\n",
      "Epoch 34/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1830 - accuracy: 0.9495 - val_loss: 0.1703 - val_accuracy: 0.9589\n",
      "Epoch 35/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1869 - accuracy: 0.9501 - val_loss: 0.1972 - val_accuracy: 0.9396\n",
      "Epoch 36/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1706 - accuracy: 0.9527 - val_loss: 0.1703 - val_accuracy: 0.9523\n",
      "Epoch 37/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1699 - accuracy: 0.9554 - val_loss: 0.1811 - val_accuracy: 0.9523\n",
      "Epoch 38/200\n",
      "130/130 [==============================] - 4s 35ms/step - loss: 0.1785 - accuracy: 0.9519 - val_loss: 0.1737 - val_accuracy: 0.9565\n",
      "Epoch 39/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1639 - accuracy: 0.9580 - val_loss: 0.1695 - val_accuracy: 0.9535\n",
      "Epoch 40/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1637 - accuracy: 0.9541 - val_loss: 0.1583 - val_accuracy: 0.9595\n",
      "Epoch 41/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.1618 - accuracy: 0.9566 - val_loss: 0.1578 - val_accuracy: 0.9626\n",
      "Epoch 42/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1616 - accuracy: 0.9582 - val_loss: 0.1583 - val_accuracy: 0.9547\n",
      "Epoch 43/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1562 - accuracy: 0.9604 - val_loss: 0.1631 - val_accuracy: 0.9571\n",
      "Epoch 44/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1496 - accuracy: 0.9629 - val_loss: 0.1332 - val_accuracy: 0.9644\n",
      "Epoch 45/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.1478 - accuracy: 0.9611 - val_loss: 0.1388 - val_accuracy: 0.9614\n",
      "Epoch 46/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.1496 - accuracy: 0.9593 - val_loss: 0.1592 - val_accuracy: 0.9499\n",
      "Epoch 47/200\n",
      "130/130 [==============================] - 4s 35ms/step - loss: 0.1409 - accuracy: 0.9642 - val_loss: 0.1433 - val_accuracy: 0.9674\n",
      "Epoch 48/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.1278 - accuracy: 0.9655 - val_loss: 0.1395 - val_accuracy: 0.9644\n",
      "Epoch 49/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.1303 - accuracy: 0.9670 - val_loss: 0.1322 - val_accuracy: 0.9632\n",
      "Epoch 50/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.1290 - accuracy: 0.9669 - val_loss: 0.1246 - val_accuracy: 0.9704\n",
      "Epoch 51/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.1230 - accuracy: 0.9677 - val_loss: 0.1294 - val_accuracy: 0.9698\n",
      "Epoch 52/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.1248 - accuracy: 0.9704 - val_loss: 0.1280 - val_accuracy: 0.9668\n",
      "Epoch 53/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.1206 - accuracy: 0.9687 - val_loss: 0.1270 - val_accuracy: 0.9638\n",
      "Epoch 54/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.1230 - accuracy: 0.9677 - val_loss: 0.1048 - val_accuracy: 0.9746\n",
      "Epoch 55/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.1206 - accuracy: 0.9676 - val_loss: 0.1080 - val_accuracy: 0.9740\n",
      "Epoch 56/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.1212 - accuracy: 0.9714 - val_loss: 0.1127 - val_accuracy: 0.9734\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 5s 37ms/step - loss: 0.1088 - accuracy: 0.9714 - val_loss: 0.1251 - val_accuracy: 0.9722\n",
      "Epoch 58/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.1081 - accuracy: 0.9739 - val_loss: 0.0985 - val_accuracy: 0.9819\n",
      "Epoch 59/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.1037 - accuracy: 0.9735 - val_loss: 0.1095 - val_accuracy: 0.9764\n",
      "Epoch 60/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.0989 - accuracy: 0.9762 - val_loss: 0.1138 - val_accuracy: 0.9716\n",
      "Epoch 61/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0968 - accuracy: 0.9778 - val_loss: 0.1146 - val_accuracy: 0.9704\n",
      "Epoch 62/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0996 - accuracy: 0.9735 - val_loss: 0.1052 - val_accuracy: 0.9734\n",
      "Epoch 63/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1013 - accuracy: 0.9760 - val_loss: 0.0868 - val_accuracy: 0.9819\n",
      "Epoch 64/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0992 - accuracy: 0.9761 - val_loss: 0.1012 - val_accuracy: 0.9777\n",
      "Epoch 65/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.1035 - accuracy: 0.9743 - val_loss: 0.0967 - val_accuracy: 0.9758\n",
      "Epoch 66/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0935 - accuracy: 0.9781 - val_loss: 0.1130 - val_accuracy: 0.9716\n",
      "Epoch 67/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0860 - accuracy: 0.9792 - val_loss: 0.0768 - val_accuracy: 0.9843\n",
      "Epoch 68/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0938 - accuracy: 0.9796 - val_loss: 0.0974 - val_accuracy: 0.9758\n",
      "Epoch 69/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0869 - accuracy: 0.9790 - val_loss: 0.0796 - val_accuracy: 0.9819\n",
      "Epoch 70/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0827 - accuracy: 0.9792 - val_loss: 0.0826 - val_accuracy: 0.9855\n",
      "Epoch 71/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0824 - accuracy: 0.9797 - val_loss: 0.0867 - val_accuracy: 0.9819\n",
      "Epoch 72/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0847 - accuracy: 0.9791 - val_loss: 0.0923 - val_accuracy: 0.9789\n",
      "Epoch 73/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0888 - accuracy: 0.9772 - val_loss: 0.0863 - val_accuracy: 0.9819\n",
      "Epoch 74/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0774 - accuracy: 0.9836 - val_loss: 0.0803 - val_accuracy: 0.9801\n",
      "Epoch 75/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.0768 - accuracy: 0.9831 - val_loss: 0.0771 - val_accuracy: 0.9825\n",
      "Epoch 76/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0747 - accuracy: 0.9827 - val_loss: 0.0761 - val_accuracy: 0.9843\n",
      "Epoch 77/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.0737 - accuracy: 0.9854 - val_loss: 0.0817 - val_accuracy: 0.9831\n",
      "Epoch 78/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0731 - accuracy: 0.9842 - val_loss: 0.0819 - val_accuracy: 0.9819\n",
      "Epoch 79/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0712 - accuracy: 0.9839 - val_loss: 0.0675 - val_accuracy: 0.9891\n",
      "Epoch 80/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0667 - accuracy: 0.9848 - val_loss: 0.0735 - val_accuracy: 0.9867\n",
      "Epoch 81/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0680 - accuracy: 0.9844 - val_loss: 0.0628 - val_accuracy: 0.9867\n",
      "Epoch 82/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0691 - accuracy: 0.9855 - val_loss: 0.0619 - val_accuracy: 0.9855\n",
      "Epoch 83/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0670 - accuracy: 0.9857 - val_loss: 0.0807 - val_accuracy: 0.9777\n",
      "Epoch 84/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0689 - accuracy: 0.9839 - val_loss: 0.0655 - val_accuracy: 0.9867\n",
      "Epoch 85/200\n",
      "130/130 [==============================] - 4s 33ms/step - loss: 0.0648 - accuracy: 0.9873 - val_loss: 0.0675 - val_accuracy: 0.9819\n",
      "Epoch 86/200\n",
      "130/130 [==============================] - 4s 33ms/step - loss: 0.0629 - accuracy: 0.9856 - val_loss: 0.0641 - val_accuracy: 0.9885\n",
      "Epoch 87/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0595 - accuracy: 0.9878 - val_loss: 0.0581 - val_accuracy: 0.9867\n",
      "Epoch 88/200\n",
      "130/130 [==============================] - 4s 33ms/step - loss: 0.0676 - accuracy: 0.9862 - val_loss: 0.0744 - val_accuracy: 0.9807\n",
      "Epoch 89/200\n",
      "130/130 [==============================] - 4s 33ms/step - loss: 0.0617 - accuracy: 0.9864 - val_loss: 0.0541 - val_accuracy: 0.9849\n",
      "Epoch 90/200\n",
      "130/130 [==============================] - 4s 33ms/step - loss: 0.0624 - accuracy: 0.9859 - val_loss: 0.0796 - val_accuracy: 0.9758\n",
      "Epoch 91/200\n",
      "130/130 [==============================] - 4s 33ms/step - loss: 0.0571 - accuracy: 0.9878 - val_loss: 0.0629 - val_accuracy: 0.9897\n",
      "Epoch 92/200\n",
      "130/130 [==============================] - 4s 35ms/step - loss: 0.0591 - accuracy: 0.9866 - val_loss: 0.0605 - val_accuracy: 0.9879\n",
      "Epoch 93/200\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.0544 - accuracy: 0.9865 - val_loss: 0.0473 - val_accuracy: 0.9897\n",
      "Epoch 94/200\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0521 - accuracy: 0.9885 - val_loss: 0.0521 - val_accuracy: 0.9885\n",
      "Epoch 95/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.0550 - accuracy: 0.9872 - val_loss: 0.0581 - val_accuracy: 0.9849\n",
      "Epoch 96/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0516 - accuracy: 0.9894 - val_loss: 0.0562 - val_accuracy: 0.9867\n",
      "Epoch 97/200\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.0550 - accuracy: 0.9871 - val_loss: 0.0596 - val_accuracy: 0.9861\n",
      "Epoch 98/200\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.0502 - accuracy: 0.9892 - val_loss: 0.0506 - val_accuracy: 0.9891\n",
      "Epoch 99/200\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.0549 - accuracy: 0.9880 - val_loss: 0.0589 - val_accuracy: 0.9861\n",
      "Epoch 100/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.0486 - accuracy: 0.9895 - val_loss: 0.0451 - val_accuracy: 0.9934\n",
      "Epoch 101/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0480 - accuracy: 0.9912 - val_loss: 0.0458 - val_accuracy: 0.9897\n",
      "Epoch 102/200\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0511 - accuracy: 0.9883 - val_loss: 0.0508 - val_accuracy: 0.9891\n",
      "Epoch 103/200\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0544 - accuracy: 0.9866 - val_loss: 0.0537 - val_accuracy: 0.9867\n",
      "Epoch 104/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0502 - accuracy: 0.9896 - val_loss: 0.0477 - val_accuracy: 0.9891\n",
      "Epoch 105/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0442 - accuracy: 0.9900 - val_loss: 0.0517 - val_accuracy: 0.9867\n",
      "Epoch 106/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0460 - accuracy: 0.9912 - val_loss: 0.0413 - val_accuracy: 0.9879\n",
      "Epoch 107/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0471 - accuracy: 0.9907 - val_loss: 0.0426 - val_accuracy: 0.9891\n",
      "Epoch 108/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0400 - accuracy: 0.9908 - val_loss: 0.0470 - val_accuracy: 0.9891\n",
      "Epoch 109/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0420 - accuracy: 0.9917 - val_loss: 0.0514 - val_accuracy: 0.9873\n",
      "Epoch 110/200\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.0396 - accuracy: 0.9928 - val_loss: 0.0441 - val_accuracy: 0.9915\n",
      "Epoch 111/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0417 - accuracy: 0.9914 - val_loss: 0.0478 - val_accuracy: 0.9891\n",
      "Epoch 112/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0380 - accuracy: 0.9914 - val_loss: 0.0338 - val_accuracy: 0.9940\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0416 - accuracy: 0.9896 - val_loss: 0.0321 - val_accuracy: 0.9915\n",
      "Epoch 114/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0412 - accuracy: 0.9911 - val_loss: 0.0362 - val_accuracy: 0.9915\n",
      "Epoch 115/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0415 - accuracy: 0.9913 - val_loss: 0.0351 - val_accuracy: 0.9934\n",
      "Epoch 116/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0357 - accuracy: 0.9931 - val_loss: 0.0345 - val_accuracy: 0.9940\n",
      "Epoch 117/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0380 - accuracy: 0.9924 - val_loss: 0.0347 - val_accuracy: 0.9940\n",
      "Epoch 118/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0377 - accuracy: 0.9911 - val_loss: 0.0397 - val_accuracy: 0.9928\n",
      "Epoch 119/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0348 - accuracy: 0.9926 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 120/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0348 - accuracy: 0.9930 - val_loss: 0.0491 - val_accuracy: 0.9897\n",
      "Epoch 121/200\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0360 - accuracy: 0.9923 - val_loss: 0.0437 - val_accuracy: 0.9867\n",
      "Epoch 122/200\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0366 - accuracy: 0.9924 - val_loss: 0.0396 - val_accuracy: 0.9903\n",
      "Epoch 123/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0336 - accuracy: 0.9932 - val_loss: 0.0361 - val_accuracy: 0.9934\n",
      "Epoch 124/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0347 - accuracy: 0.9919 - val_loss: 0.0324 - val_accuracy: 0.9940\n",
      "Epoch 125/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0325 - accuracy: 0.9929 - val_loss: 0.0288 - val_accuracy: 0.9921\n",
      "Epoch 126/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0315 - accuracy: 0.9929 - val_loss: 0.0437 - val_accuracy: 0.9921\n",
      "Epoch 127/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0341 - accuracy: 0.9932 - val_loss: 0.0309 - val_accuracy: 0.9940\n",
      "Epoch 128/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0328 - accuracy: 0.9934 - val_loss: 0.0363 - val_accuracy: 0.9921\n",
      "Epoch 129/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0300 - accuracy: 0.9948 - val_loss: 0.0289 - val_accuracy: 0.9940\n",
      "Epoch 130/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 0.0327 - val_accuracy: 0.9921\n",
      "Epoch 131/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.0382 - val_accuracy: 0.9915\n",
      "Epoch 132/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0257 - accuracy: 0.9952 - val_loss: 0.0335 - val_accuracy: 0.9915\n",
      "Epoch 133/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0290 - accuracy: 0.9938 - val_loss: 0.0393 - val_accuracy: 0.9909\n",
      "Epoch 134/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.0302 - val_accuracy: 0.9940\n",
      "Epoch 135/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0248 - accuracy: 0.9948 - val_loss: 0.0267 - val_accuracy: 0.9946\n",
      "Epoch 136/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0297 - accuracy: 0.9940 - val_loss: 0.0270 - val_accuracy: 0.9940\n",
      "Epoch 137/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.0371 - val_accuracy: 0.9897\n",
      "Epoch 138/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0274 - accuracy: 0.9944 - val_loss: 0.0288 - val_accuracy: 0.9934\n",
      "Epoch 139/200\n",
      "130/130 [==============================] - 4s 35ms/step - loss: 0.0276 - accuracy: 0.9932 - val_loss: 0.0350 - val_accuracy: 0.9903\n",
      "Epoch 140/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0307 - accuracy: 0.9936 - val_loss: 0.0359 - val_accuracy: 0.9909\n",
      "Epoch 141/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0232 - accuracy: 0.9954 - val_loss: 0.0246 - val_accuracy: 0.9934\n",
      "Epoch 142/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0264 - accuracy: 0.9948 - val_loss: 0.0265 - val_accuracy: 0.9952\n",
      "Epoch 143/200\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 0.0230 - val_accuracy: 0.9958\n",
      "Epoch 144/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0242 - accuracy: 0.9943 - val_loss: 0.0324 - val_accuracy: 0.9946\n",
      "Epoch 145/200\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.0283 - accuracy: 0.9936 - val_loss: 0.0281 - val_accuracy: 0.9952\n",
      "Epoch 146/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0245 - accuracy: 0.9935 - val_loss: 0.0359 - val_accuracy: 0.9903\n",
      "Epoch 147/200\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 0.0312 - val_accuracy: 0.9928\n",
      "Epoch 148/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0203 - accuracy: 0.9963 - val_loss: 0.0196 - val_accuracy: 0.9958\n",
      "Epoch 149/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0255 - accuracy: 0.9946 - val_loss: 0.0187 - val_accuracy: 0.9958\n",
      "Epoch 150/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 0.0278 - val_accuracy: 0.9952\n",
      "Epoch 151/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0241 - accuracy: 0.9952 - val_loss: 0.0234 - val_accuracy: 0.9921\n",
      "Epoch 152/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0242 - accuracy: 0.9953 - val_loss: 0.0182 - val_accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0231 - accuracy: 0.9953 - val_loss: 0.0336 - val_accuracy: 0.9915\n",
      "Epoch 154/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.0317 - val_accuracy: 0.9940\n",
      "Epoch 155/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0230 - val_accuracy: 0.9958\n",
      "Epoch 156/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0222 - accuracy: 0.9943 - val_loss: 0.0168 - val_accuracy: 0.9970\n",
      "Epoch 157/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.0289 - val_accuracy: 0.9934\n",
      "Epoch 158/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0217 - accuracy: 0.9957 - val_loss: 0.0282 - val_accuracy: 0.9934\n",
      "Epoch 159/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0239 - val_accuracy: 0.9958\n",
      "Epoch 160/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.0260 - val_accuracy: 0.9958\n",
      "Epoch 161/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.0199 - val_accuracy: 0.9964\n",
      "Epoch 162/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 0.0182 - val_accuracy: 0.9964\n",
      "Epoch 163/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0282 - val_accuracy: 0.9934\n",
      "Epoch 164/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.0310 - val_accuracy: 0.9921\n",
      "Epoch 165/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0293 - val_accuracy: 0.9946\n",
      "Epoch 166/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0207 - accuracy: 0.9955 - val_loss: 0.0225 - val_accuracy: 0.9946\n",
      "Epoch 167/200\n",
      "130/130 [==============================] - 4s 34ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.0292 - val_accuracy: 0.9952\n",
      "Epoch 168/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0223 - accuracy: 0.9952 - val_loss: 0.0262 - val_accuracy: 0.9940\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 5s 38ms/step - loss: 0.0176 - accuracy: 0.9965 - val_loss: 0.0289 - val_accuracy: 0.9946\n",
      "Epoch 170/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0177 - accuracy: 0.9967 - val_loss: 0.0244 - val_accuracy: 0.9946\n",
      "Epoch 171/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0291 - val_accuracy: 0.9909\n",
      "Epoch 172/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0155 - accuracy: 0.9976 - val_loss: 0.0177 - val_accuracy: 0.9964\n",
      "Epoch 173/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0168 - accuracy: 0.9971 - val_loss: 0.0177 - val_accuracy: 0.9970\n",
      "Epoch 174/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.0136 - val_accuracy: 0.9958\n",
      "Epoch 175/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.0255 - val_accuracy: 0.9946\n",
      "Epoch 176/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0200 - accuracy: 0.9960 - val_loss: 0.0275 - val_accuracy: 0.9921\n",
      "Epoch 177/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 0.0154 - val_accuracy: 0.9964\n",
      "Epoch 178/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0136 - val_accuracy: 0.9964\n",
      "Epoch 179/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0314 - val_accuracy: 0.9921\n",
      "Epoch 180/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0118 - val_accuracy: 0.9970\n",
      "Epoch 181/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.0159 - val_accuracy: 0.9970\n",
      "Epoch 182/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.0194 - val_accuracy: 0.9958\n",
      "Epoch 183/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.0145 - val_accuracy: 0.9982\n",
      "Epoch 184/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.0189 - val_accuracy: 0.9970\n",
      "Epoch 185/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0145 - accuracy: 0.9981 - val_loss: 0.0183 - val_accuracy: 0.9964\n",
      "Epoch 186/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.0122 - val_accuracy: 0.9964\n",
      "Epoch 187/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.0155 - val_accuracy: 0.9970\n",
      "Epoch 188/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0202 - val_accuracy: 0.9934\n",
      "Epoch 189/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.0165 - val_accuracy: 0.9964\n",
      "Epoch 190/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.0127 - val_accuracy: 0.9970\n",
      "Epoch 191/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.0127 - val_accuracy: 0.9988\n",
      "Epoch 192/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0180 - accuracy: 0.9966 - val_loss: 0.0109 - val_accuracy: 0.9982\n",
      "Epoch 193/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0144 - val_accuracy: 0.9952\n",
      "Epoch 194/200\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 0.0150 - val_accuracy: 0.9964\n",
      "Epoch 195/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.0087 - val_accuracy: 0.9988\n",
      "Epoch 196/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.0121 - val_accuracy: 0.9976\n",
      "Epoch 197/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.0212 - val_accuracy: 0.9946\n",
      "Epoch 198/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.0208 - val_accuracy: 0.9940\n",
      "Epoch 199/200\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0151 - val_accuracy: 0.9976\n",
      "Epoch 200/200\n",
      "130/130 [==============================] - 5s 35ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.0133 - val_accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 64\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.1\n",
    "Rotation_Angle = 0\n",
    "ZoomRange = 0.0\n",
    "# Epochs = 10\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle,vertical_flip=True)\n",
    "\n",
    "# datagen = ImageDataGenerator(featurewise_center=False,\n",
    "#                                  featurewise_std_normalization=False,\n",
    "#                                  rotation_range=20,\n",
    "#                                  width_shift_range=0.2,\n",
    "#                                  height_shift_range=0.2,\n",
    "#                                  vertical_flip=True)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epochs)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_loss, final_acc = model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='../data/raw_images/sample'\n",
    "files = glob.glob(Input_dir + '/*.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/8 8\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/0 6\n",
      "../data/raw_images/sample/9 6\n",
      "../data/raw_images/sample/2 6\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/9 9\n",
      "../data/raw_images/sample/9 9\n",
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/8 6\n",
      "../data/raw_images/sample/4 6\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/3 6\n",
      "../data/raw_images/sample/0 6\n",
      "../data/raw_images/sample/3 6\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/1 7\n",
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/4 6\n",
      "../data/raw_images/sample/3 6\n",
      "../data/raw_images/sample/0 8\n",
      "../data/raw_images/sample/1 7\n",
      "../data/raw_images/sample/3 3\n",
      "../data/raw_images/sample/8 6\n",
      "../data/raw_images/sample/4 6\n",
      "../data/raw_images/sample/2 6\n",
      "../data/raw_images/sample/0 6\n",
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/2 6\n",
      "../data/raw_images/sample/9 6\n",
      "../data/raw_images/sample/8 8\n",
      "../data/raw_images/sample/4 6\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/2 6\n",
      "../data/raw_images/sample/1 7\n",
      "../data/raw_images/sample/8 6\n",
      "../data/raw_images/sample/9 6\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/1 7\n",
      "../data/raw_images/sample/3 7\n",
      "../data/raw_images/sample/0 8\n",
      "../data/raw_images/sample/4 9\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/1 7\n",
      "../data/raw_images/sample/2 6\n"
     ]
    }
   ],
   "source": [
    "for file in files[:100]: \n",
    "    base = os.path.basename(file)\n",
    "    target = base[0:1]\n",
    "    image_bmp = Image.open(file)\n",
    "    test_image = np.array(image_bmp, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,25,15,3])\n",
    "    classes = np.argmax(model.predict(img), axis=-1)\n",
    "    classes = classes[0]\n",
    "    print(file[:27], classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post training weight quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depending on your requirements (performance, memory and runtime), post training quantization can be done in two ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach #1:  Post training weight quantization (quantizes weights only) In this case only weights are quantized to int8 but activations remain as they were. Inference input and output are floating-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 23:53:48.077321: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgg7_66_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 23:53:48.495790: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-10-13 23:53:48.495922: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-10-13 23:53:48.497375: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n",
      "2022-10-13 23:53:48.527752: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2022-10-13 23:53:48.527778: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2022-10-13 23:53:48.529934: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-10-13 23:53:48.541855: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential_3/conv2d_9/Conv2D because it has fewer than 1024 elements (864).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16608"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.experimental_new_converter = True\n",
    "# Post training quantization\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_quant_model = converter.convert()\n",
    "open(\"digit_model_quant.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for n in range(1000):\n",
    "        data = np.expand_dims(x_data[5], axis=0)\n",
    "        yield [data.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach #2: Full integer quantization (Quantizes weights and activations) In this case weights and activations are quantized to int8. First we need to follow the approach #1 to quantize weight and then implement following code to do full integer quantization. This uses quantized input and output, making it compatible with more accelerators, such as the Openmv Camera and Coral Edge TPU. Inference input and output are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp574fg52j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp574fg52j/assets\n",
      "2022-10-13 23:53:57.786799: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-10-13 23:53:57.786924: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-10-13 23:53:57.788418: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-10-13 23:53:57.819546: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2022-10-13 23:53:57.819573: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15120"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.target_spec.supported_types = [tf.dtypes.int8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model_quant = converter.convert()\n",
    "open(\"digit_model_quant.tflite_int8.tflite\", \"wb\").write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
