{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. \n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFliteNamingAndVersion = \"testing\"   # Used for tflite Filename\n",
    "Training_Percentage = 0.3              # 0.0 = Use all Images for Training\n",
    "Epochs = 100\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 15x25 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8279, 25, 15, 3)\n",
      "(8279, 10)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='../data/raw_images/labelled_bmp_data_equal_combined_final'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.bmp')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for file in files:\n",
    "    base = os.path.basename(file)\n",
    "    target = base[0:1]\n",
    "    category = int(target)\n",
    "    test_image = Image.open(file)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    x_data.append(test_image)\n",
    "    y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)/255\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 10)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8279"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5795"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.6275, 0.7373, 0.6588],\n",
       "        [0.6275, 0.7373, 0.6902],\n",
       "        [0.6275, 0.7373, 0.6588],\n",
       "        ...,\n",
       "        [0.7529, 0.8627, 0.8157],\n",
       "        [0.7843, 0.8941, 0.8471],\n",
       "        [0.7843, 0.9098, 0.8471]],\n",
       "\n",
       "       [[0.6275, 0.7373, 0.6588],\n",
       "        [0.6275, 0.7373, 0.6588],\n",
       "        [0.6275, 0.7373, 0.6588],\n",
       "        ...,\n",
       "        [0.7529, 0.8784, 0.8471],\n",
       "        [0.7843, 0.9098, 0.8471],\n",
       "        [0.8157, 0.9255, 0.8471]],\n",
       "\n",
       "       [[0.6275, 0.7216, 0.6588],\n",
       "        [0.6275, 0.7216, 0.6588],\n",
       "        [0.6275, 0.7216, 0.6588],\n",
       "        ...,\n",
       "        [0.7529, 0.8784, 0.8157],\n",
       "        [0.7843, 0.9098, 0.8471],\n",
       "        [0.8157, 0.9255, 0.8471]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.5647, 0.6745, 0.6275],\n",
       "        [0.5961, 0.7059, 0.6588],\n",
       "        [0.5647, 0.6745, 0.6275],\n",
       "        ...,\n",
       "        [0.6902, 0.7529, 0.7216],\n",
       "        [0.6902, 0.7686, 0.7216],\n",
       "        [0.6902, 0.7843, 0.7529]],\n",
       "\n",
       "       [[0.5647, 0.6588, 0.6275],\n",
       "        [0.5647, 0.6902, 0.6588],\n",
       "        [0.5647, 0.6745, 0.6275],\n",
       "        ...,\n",
       "        [0.6588, 0.7216, 0.6902],\n",
       "        [0.6275, 0.7373, 0.6902],\n",
       "        [0.6588, 0.7373, 0.7216]],\n",
       "\n",
       "       [[0.5647, 0.6588, 0.6275],\n",
       "        [0.5647, 0.6745, 0.6275],\n",
       "        [0.5647, 0.6745, 0.6275],\n",
       "        ...,\n",
       "        [0.5961, 0.6902, 0.6275],\n",
       "        [0.5961, 0.6902, 0.6275],\n",
       "        [0.6275, 0.6902, 0.6275]]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (15, 25, 3)\n",
    "* Number of output layers: 10\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(25,15,3)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activity_regularizer=regularizers.L2(1e-5),  activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=3, padding='same',activity_regularizer=regularizers.L2(1e-5), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, kernel_size=3, padding='same',activity_regularizer=regularizers.L2(1e-5), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 25, 15, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 13, 8, 32)         18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 7, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 4, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 33,786\n",
      "Trainable params: 33,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 8.0403 - accuracy: 0.3362 - val_loss: 1.3940 - val_accuracy: 0.6832\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 1.1941 - accuracy: 0.6648 - val_loss: 0.9206 - val_accuracy: 0.7415\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.6671 - accuracy: 0.8406 - val_loss: 0.5411 - val_accuracy: 0.8941\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.4173 - accuracy: 0.9167 - val_loss: 0.2487 - val_accuracy: 0.9605\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.2925 - accuracy: 0.9479 - val_loss: 0.1712 - val_accuracy: 0.9851\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.2542 - accuracy: 0.9578 - val_loss: 0.1590 - val_accuracy: 0.9879\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.2017 - accuracy: 0.9682 - val_loss: 0.1231 - val_accuracy: 0.9863\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.1677 - accuracy: 0.9779 - val_loss: 0.0958 - val_accuracy: 0.9944\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.2202 - accuracy: 0.9644 - val_loss: 0.0906 - val_accuracy: 0.9960\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.1197 - accuracy: 0.9873 - val_loss: 0.0809 - val_accuracy: 0.9968\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.1524 - accuracy: 0.9752 - val_loss: 0.0804 - val_accuracy: 0.9936\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.1069 - accuracy: 0.9879 - val_loss: 0.0608 - val_accuracy: 0.9992\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 6s 48ms/step - loss: 0.0969 - accuracy: 0.9886 - val_loss: 0.0633 - val_accuracy: 0.9980\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.1133 - accuracy: 0.9825 - val_loss: 0.0623 - val_accuracy: 0.9980\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.0991 - accuracy: 0.9872 - val_loss: 0.0684 - val_accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 64\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.1\n",
    "Rotation_Angle = 0\n",
    "ZoomRange = 0.0\n",
    "# Epochs = 10\n",
    "callback = []\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "                    monitor=\"val_accuracy\",\n",
    "                    min_delta=0,\n",
    "                    patience=3,\n",
    "                    verbose=0,\n",
    "                    mode=\"auto\",\n",
    "                    baseline=None,\n",
    "                    restore_best_weights=False,\n",
    "                )\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle,vertical_flip=True)\n",
    "\n",
    "# datagen = ImageDataGenerator(featurewise_center=False,\n",
    "#                                  featurewise_std_normalization=False,\n",
    "#                                  rotation_range=20,\n",
    "#                                  width_shift_range=0.2,\n",
    "#                                  height_shift_range=0.2,\n",
    "#                                  vertical_flip=True)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size, shuffle = True)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size, shuffle = False)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epochs, callbacks=[early_stopping])\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size, shuffle = True,)\n",
    "    history = model.fit(train_iterator, epochs = Epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 3ms/step - loss: 2.2664 - accuracy: 0.1634\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='../data/raw_images/sample'\n",
    "files = glob.glob(Input_dir + '/*.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/8 8\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/0 8\n",
      "../data/raw_images/sample/9 8\n",
      "../data/raw_images/sample/2 5\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/9 9\n",
      "../data/raw_images/sample/9 9\n",
      "../data/raw_images/sample/5 5\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/8 8\n",
      "../data/raw_images/sample/4 8\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/3 3\n",
      "../data/raw_images/sample/0 8\n",
      "../data/raw_images/sample/3 3\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/1 1\n",
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/4 8\n",
      "../data/raw_images/sample/3 3\n",
      "../data/raw_images/sample/0 8\n",
      "../data/raw_images/sample/1 1\n",
      "../data/raw_images/sample/3 3\n",
      "../data/raw_images/sample/8 8\n",
      "../data/raw_images/sample/4 4\n",
      "../data/raw_images/sample/2 5\n",
      "../data/raw_images/sample/0 8\n",
      "../data/raw_images/sample/5 6\n",
      "../data/raw_images/sample/2 6\n",
      "../data/raw_images/sample/9 9\n",
      "../data/raw_images/sample/8 8\n",
      "../data/raw_images/sample/4 4\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/2 6\n",
      "../data/raw_images/sample/1 1\n",
      "../data/raw_images/sample/8 8\n",
      "../data/raw_images/sample/9 9\n",
      "../data/raw_images/sample/7 7\n",
      "../data/raw_images/sample/1 1\n",
      "../data/raw_images/sample/3 3\n",
      "../data/raw_images/sample/0 8\n",
      "../data/raw_images/sample/4 4\n",
      "../data/raw_images/sample/6 6\n",
      "../data/raw_images/sample/1 1\n",
      "../data/raw_images/sample/2 5\n"
     ]
    }
   ],
   "source": [
    "for file in files[:100]: \n",
    "    base = os.path.basename(file)\n",
    "    target = base[0:1]\n",
    "    image_bmp = Image.open(file)\n",
    "    test_image = np.array(image_bmp, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,25,15,3])\n",
    "    classes = np.argmax(model.predict(img), axis=-1)\n",
    "    classes = classes[0]\n",
    "    print(file[:27], classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.8157, 0.7529, 0.8627, 0.8157, 0.7529, 0.8627, 0.8157, 0.7216, 0.8627, 0.8157, 0.7216, 0.8627, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.7843, 0.7529, 0.6588, 0.7373, 0.7216, 0.7216, 0.8471, 0.7843, 0.7216, 0.8627, 0.7843, 0.7216, 0.8627, 0.7843, 0.7529, 0.8627, 0.8157, 0.7216, 0.8627, 0.8157, 0.7216, 0.8471, 0.7843, 0.7216, 0.8314, 0.7843, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8627, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8314, 0.7843, 0.7216, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.8000, 0.7529, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.7216, 0.8314, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.6902, 0.8314, 0.7843, 0.6902, 0.8000, 0.7529, 0.6588, 0.7686, 0.7529, 0.6588, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6588, 0.7529, 0.6902, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8314, 0.7529, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7843, 0.6588, 0.8000, 0.7529, 0.6588, 0.7529, 0.7529, 0.6275, 0.7373, 0.7216, 0.6275, 0.7059, 0.7216, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7216, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7529, 0.6902, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8000, 0.7843, 0.6275, 0.7529, 0.7216, 0.6275, 0.7216, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7216, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.7216, 0.7216, 0.6588, 0.7529, 0.7529, 0.6588, 0.8000, 0.7529, 0.6588, 0.8000, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.7059, 0.6902, 0.6588, 0.7216, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.7373, 0.6902, 0.6902, 0.7843, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.6902, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7843, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6902, 0.7843, 0.7529, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8000, 0.7529, 0.6275, 0.7529, 0.6902, 0.5961, 0.6902, 0.6588, 0.6275, 0.7216, 0.6902, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7686, 0.7529, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6902, 0.7843, 0.7843, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.6902, 0.5961, 0.6902, 0.6588, 0.6275, 0.7216, 0.6902, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7529, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7373, 0.6902, 0.6902, 0.7843, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.6902, 0.5961, 0.6902, 0.6588, 0.6588, 0.7373, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7686, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7373, 0.6902, 0.6902, 0.7686, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7529, 0.7216, 0.6902, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7686, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7216, 0.6902, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7529, 0.7216, 0.6588, 0.7529, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7373, 0.6902, 0.6588, 0.7686, 0.7216, 0.6902, 0.8000, 0.7529, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7843, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7216, 0.7216, 0.6588, 0.7686, 0.7216, 0.6902, 0.7843, 0.7529, 0.6902, 0.8000, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6588, 0.7529, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7216, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7216, 0.6902, 0.6275, 0.7216, 0.7216, 0.6588, 0.7529, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7686, 0.6902, 0.6275, 0.7059, 0.6588, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.8000, 0.7216, 0.6902, 0.7843, 0.7216, 0.6902, 0.7843, 0.7529, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.7216, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7529, 0.7216, 0.6588, 0.7373, 0.6902, 0.6275, 0.7059, 0.6588, 0.6902, 0.8000, 0.7216, 0.6588, 0.8000, 0.7216, 0.6902, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6902, 0.8000, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.7843, 0.7216, 0.6588, 0.7373, 0.7216, 0.5961, 0.6902, 0.6588, 0.6275, 0.7059, 0.6588, 0.6588, 0.7373, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7373, 0.6902, 0.6275, 0.7059, 0.6588, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7843, 0.7216, 0.6902, 0.8000, 0.7216, 0.6902, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6275, 0.7216, 0.6902, 0.5961, 0.6745, 0.6588, 0.6275, 0.6902, 0.6588, 0.6588, 0.7216, 0.6902, 0.6588, 0.7373, 0.6902, 0.6588, 0.7216, 0.6902, 0.6275, 0.6902, 0.6588, 0.6588, 0.7529, 0.6902, 0.6588, 0.7529, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7529, 0.6902, 0.6275, 0.6902, 0.6588, 0.5961, 0.6588, 0.6588, 0.5961, 0.6745, 0.6588, 0.6275, 0.7059, 0.6902, 0.6588, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.6902, 0.6588, 0.6588, 0.7373, 0.6902, 0.6588, 0.7373, 0.6902, 0.6588, 0.7216, 0.6902, 0.6588, 0.7216, 0.6902, 0.6588, 0.7529, 0.6902, 0.6588, 0.7529, 0.6902, 0.6588, 0.7373, 0.6902, 0.6275, 0.7059, 0.6902, 0.5961, 0.6745, 0.6588, 0.5647, 0.6588, 0.6275, 0.5961, 0.6745, 0.6275, 0.6275, 0.7059, 0.6588, 0.6275, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.6275, 0.6745, 0.6275, 0.6588, 0.7216, 0.6902, 0.6588, 0.7216, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.6902, 0.6588, 0.6275, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.6275, 0.6902, 0.6588, 0.5961, 0.6745, 0.6275, 0.5647, 0.6588, 0.5961, 0.5333, 0.6431, 0.5961, 0.5647, 0.6588, 0.6275, 0.5961, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.6275, 0.6902, 0.6588, 0.5961, 0.6745, 0.6275, 0.6275, 0.7059, 0.6588, 0.6275, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.5961, 0.6745, 0.6275, 0.5647, 0.6588, 0.5961, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5961, 0.5333, 0.6431, 0.5961, 0.5333, 0.6275, 0.5647, 0.5647, 0.6431, 0.5961, 0.5961, 0.6902, 0.6275, 0.5961, 0.6745, 0.6275, 0.5961, 0.6588, 0.6275, 0.5961, 0.6588, 0.5961, 0.5961, 0.6745, 0.6275, 0.5961, 0.6745, 0.6275, 0.5961, 0.6745, 0.6275, 0.5647, 0.6431, 0.5961, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5333, 0.6118, 0.5647, 0.5333, 0.6275, 0.5647, 0.5647, 0.6431, 0.5647, 0.5647, 0.6588, 0.5961, 0.5647, 0.6588, 0.5961, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5647, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5961, 0.5333, 0.6431, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.4706, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.6118, 0.5333, 0.5333, 0.6275, 0.5647, 0.5333, 0.6275, 0.5647, 0.5647, 0.6275, 0.5647, 0.5333, 0.6275, 0.5647, 0.5333, 0.6275, 0.5647, 0.5333, 0.6118, 0.5647, 0.5333, 0.6275, 0.5647, 0.5333, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5804, 0.5333, 0.5020, 0.5804, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5333, 0.5961, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5333, 0.6118, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post training weight quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depending on your requirements (performance, memory and runtime), post training quantization can be done in two ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach #1:  Post training weight quantization (quantizes weights only) In this case only weights are quantized to int8 but activations remain as they were. Inference input and output are floating-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 01:52:15.347649: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnrg9d28g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 01:52:15.903410: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-10-14 01:52:15.903573: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-10-14 01:52:15.905085: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.009ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-10-14 01:52:15.943949: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2022-10-14 01:52:15.943999: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2022-10-14 01:52:15.947120: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-10-14 01:52:15.961495: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential_2/conv2d_6/Conv2D because it has fewer than 1024 elements (864).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62704"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.experimental_new_converter = True\n",
    "# Post training quantization\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_quant_model = converter.convert()\n",
    "open(\"digit_model_quant.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for n in range(10):\n",
    "        data = np.expand_dims(x_data[5], axis=0)\n",
    "        yield [data.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach #2: Full integer quantization (Quantizes weights and activations) In this case weights and activations are quantized to int8. First we need to follow the approach #1 to quantize weight and then implement following code to do full integer quantization. This uses quantized input and output, making it compatible with more accelerators, such as the Openmv Camera and Coral Edge TPU. Inference input and output are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpglxxntnm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpglxxntnm/assets\n",
      "2022-10-14 01:56:35.128291: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-10-14 01:56:35.128483: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-10-14 01:56:35.129911: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-10-14 01:56:35.169560: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2022-10-14 01:56:35.169589: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61392"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.target_spec.supported_types = [tf.dtypes.int8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model_quant = converter.convert()\n",
    "open(\"digit_model_quant.tflite_int8.tflite\", \"wb\").write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.8157, 0.7529, 0.8627, 0.8157, 0.7529, 0.8627, 0.8157, 0.7216, 0.8627, 0.8157, 0.7216, 0.8627, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.7843, 0.7529, 0.6588, 0.7373, 0.7216, 0.7216, 0.8471, 0.7843, 0.7216, 0.8627, 0.7843, 0.7216, 0.8627, 0.7843, 0.7529, 0.8627, 0.8157, 0.7216, 0.8627, 0.8157, 0.7216, 0.8471, 0.7843, 0.7216, 0.8314, 0.7843, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8627, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8314, 0.7843, 0.7216, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.8000, 0.7529, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.7216, 0.8314, 0.7843, 0.7216, 0.8471, 0.7843, 0.7216, 0.8471, 0.7843, 0.6902, 0.8314, 0.7843, 0.6902, 0.8000, 0.7529, 0.6588, 0.7686, 0.7529, 0.6588, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6588, 0.7529, 0.6902, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8314, 0.7529, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7843, 0.6588, 0.8000, 0.7529, 0.6588, 0.7529, 0.7529, 0.6275, 0.7373, 0.7216, 0.6275, 0.7059, 0.7216, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7216, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7529, 0.6902, 0.6902, 0.8314, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8000, 0.7843, 0.6275, 0.7529, 0.7216, 0.6275, 0.7216, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7216, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.7216, 0.7216, 0.6588, 0.7529, 0.7529, 0.6588, 0.8000, 0.7529, 0.6588, 0.8000, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.7059, 0.6902, 0.6588, 0.7216, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.7373, 0.6902, 0.6902, 0.7843, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7529, 0.7216, 0.6275, 0.6902, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7843, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6902, 0.7843, 0.7529, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.8000, 0.7529, 0.6275, 0.7529, 0.6902, 0.5961, 0.6902, 0.6588, 0.6275, 0.7216, 0.6902, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7686, 0.7529, 0.6275, 0.7373, 0.7216, 0.6275, 0.7373, 0.7216, 0.6902, 0.7843, 0.7843, 0.7216, 0.8314, 0.7843, 0.6902, 0.8314, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.6902, 0.5961, 0.6902, 0.6588, 0.6275, 0.7216, 0.6902, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7529, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7373, 0.6902, 0.6902, 0.7843, 0.7529, 0.6902, 0.8314, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.6902, 0.5961, 0.6902, 0.6588, 0.6588, 0.7373, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7686, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7373, 0.6902, 0.6902, 0.7686, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.7843, 0.7529, 0.6275, 0.7373, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7529, 0.7216, 0.6902, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7216, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7686, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7216, 0.6902, 0.6588, 0.7373, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7529, 0.7216, 0.6588, 0.7529, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7373, 0.6902, 0.6588, 0.7686, 0.7216, 0.6902, 0.8000, 0.7529, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6588, 0.7843, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7216, 0.7216, 0.6588, 0.7686, 0.7216, 0.6902, 0.7843, 0.7529, 0.6902, 0.8000, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.6902, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6588, 0.7529, 0.7216, 0.6275, 0.7373, 0.6902, 0.6275, 0.7216, 0.7216, 0.6275, 0.7216, 0.6902, 0.6275, 0.7216, 0.6902, 0.6275, 0.7216, 0.7216, 0.6588, 0.7529, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7686, 0.6902, 0.6275, 0.7059, 0.6588, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8157, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.8000, 0.7216, 0.6902, 0.7843, 0.7216, 0.6902, 0.7843, 0.7529, 0.6588, 0.7843, 0.7216, 0.6588, 0.7373, 0.7216, 0.6275, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7529, 0.7216, 0.6588, 0.7373, 0.6902, 0.6275, 0.7059, 0.6588, 0.6902, 0.8000, 0.7216, 0.6588, 0.8000, 0.7216, 0.6902, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6588, 0.7843, 0.7216, 0.6902, 0.8000, 0.7529, 0.6902, 0.8000, 0.7529, 0.6902, 0.7843, 0.7216, 0.6588, 0.7373, 0.7216, 0.5961, 0.6902, 0.6588, 0.6275, 0.7059, 0.6588, 0.6588, 0.7373, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7373, 0.6902, 0.6275, 0.7059, 0.6588, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7843, 0.7216, 0.6902, 0.8000, 0.7216, 0.6902, 0.7843, 0.7216, 0.6588, 0.7686, 0.7216, 0.6275, 0.7216, 0.6902, 0.5961, 0.6745, 0.6588, 0.6275, 0.6902, 0.6588, 0.6588, 0.7216, 0.6902, 0.6588, 0.7373, 0.6902, 0.6588, 0.7216, 0.6902, 0.6275, 0.6902, 0.6588, 0.6588, 0.7529, 0.6902, 0.6588, 0.7529, 0.6902, 0.6588, 0.7529, 0.7216, 0.6588, 0.7373, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7686, 0.7216, 0.6588, 0.7529, 0.6902, 0.6275, 0.6902, 0.6588, 0.5961, 0.6588, 0.6588, 0.5961, 0.6745, 0.6588, 0.6275, 0.7059, 0.6902, 0.6588, 0.7059, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.6902, 0.6588, 0.6588, 0.7373, 0.6902, 0.6588, 0.7373, 0.6902, 0.6588, 0.7216, 0.6902, 0.6588, 0.7216, 0.6902, 0.6588, 0.7529, 0.6902, 0.6588, 0.7529, 0.6902, 0.6588, 0.7373, 0.6902, 0.6275, 0.7059, 0.6902, 0.5961, 0.6745, 0.6588, 0.5647, 0.6588, 0.6275, 0.5961, 0.6745, 0.6275, 0.6275, 0.7059, 0.6588, 0.6275, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.6275, 0.6745, 0.6275, 0.6588, 0.7216, 0.6902, 0.6588, 0.7216, 0.6902, 0.6275, 0.7059, 0.6902, 0.6275, 0.6902, 0.6588, 0.6275, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.6275, 0.6902, 0.6588, 0.5961, 0.6745, 0.6275, 0.5647, 0.6588, 0.5961, 0.5333, 0.6431, 0.5961, 0.5647, 0.6588, 0.6275, 0.5961, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.6275, 0.6902, 0.6588, 0.5961, 0.6745, 0.6275, 0.6275, 0.7059, 0.6588, 0.6275, 0.7059, 0.6588, 0.6275, 0.6902, 0.6588, 0.5961, 0.6745, 0.6275, 0.5647, 0.6588, 0.5961, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5961, 0.5333, 0.6431, 0.5961, 0.5333, 0.6275, 0.5647, 0.5647, 0.6431, 0.5961, 0.5961, 0.6902, 0.6275, 0.5961, 0.6745, 0.6275, 0.5961, 0.6588, 0.6275, 0.5961, 0.6588, 0.5961, 0.5961, 0.6745, 0.6275, 0.5961, 0.6745, 0.6275, 0.5961, 0.6745, 0.6275, 0.5647, 0.6431, 0.5961, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5333, 0.6118, 0.5647, 0.5333, 0.6275, 0.5647, 0.5647, 0.6431, 0.5647, 0.5647, 0.6588, 0.5961, 0.5647, 0.6588, 0.5961, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5647, 0.5647, 0.6431, 0.5961, 0.5647, 0.6431, 0.5961, 0.5333, 0.6431, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.4706, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.6118, 0.5333, 0.5333, 0.6275, 0.5647, 0.5333, 0.6275, 0.5647, 0.5647, 0.6275, 0.5647, 0.5333, 0.6275, 0.5647, 0.5333, 0.6275, 0.5647, 0.5333, 0.6118, 0.5647, 0.5333, 0.6275, 0.5647, 0.5333, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5804, 0.5333, 0.5020, 0.5804, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5333, 0.5961, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5333, 0.6118, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [0.5020, 0.6118, 0.5333, 0.5020, 0.6431, 0.5647, 0.5333, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6431, 0.5333, 0.5020, 0.6431, 0.5333, 0.5020, 0.6431, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6431, 0.5333, 0.5020, 0.6431, 0.5333, 0.5020, 0.6431, 0.5333, 0.5020, 0.6431, 0.5647, 0.5020, 0.6118, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6431, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5333, 0.6431, 0.5647, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5333, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6431, 0.5333, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.4392, 0.5804, 0.5020, 0.4392, 0.5490, 0.5020, 0.4706, 0.5961, 0.5020, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5647, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.4706, 0.5961, 0.5020, 0.4078, 0.5333, 0.4392, 0.3765, 0.5176, 0.4392, 0.4392, 0.5804, 0.4706, 0.5020, 0.6118, 0.5020, 0.5020, 0.6275, 0.5333, 0.4706, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.4706, 0.6275, 0.5333, 0.4706, 0.6118, 0.5020, 0.4706, 0.6118, 0.5020, 0.4706, 0.6118, 0.5020, 0.4392, 0.5647, 0.4706, 0.3765, 0.5176, 0.4392, 0.3765, 0.5176, 0.4392, 0.4706, 0.5804, 0.4706, 0.5020, 0.6118, 0.5020, 0.5020, 0.6118, 0.5333, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.4706, 0.6118, 0.5333, 0.4706, 0.6275, 0.5333, 0.4706, 0.6275, 0.5020, 0.4706, 0.5961, 0.5333, 0.4392, 0.5647, 0.5020, 0.3765, 0.5020, 0.4392, 0.3765, 0.5176, 0.4706, 0.4706, 0.5961, 0.5020, 0.5020, 0.6118, 0.5020, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.4706, 0.6118, 0.5333, 0.4706, 0.6118, 0.5333, 0.4706, 0.5961, 0.5333, 0.4392, 0.5490, 0.5020, 0.3765, 0.5020, 0.4392, 0.3765, 0.5176, 0.4706, 0.4392, 0.5804, 0.5020, 0.4706, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.4706, 0.6118, 0.5333, 0.4706, 0.6118, 0.5333, 0.4706, 0.5961, 0.5333, 0.4078, 0.5490, 0.4706, 0.3765, 0.4863, 0.4392, 0.4078, 0.5176, 0.4706, 0.4706, 0.5961, 0.5020, 0.4706, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6118, 0.5333, 0.4706, 0.6118, 0.5333, 0.4078, 0.5490, 0.4706, 0.3765, 0.5020, 0.4392, 0.4078, 0.5333, 0.4706, 0.4706, 0.5961, 0.5020, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5333, 0.5020, 0.6275, 0.5333, 0.4706, 0.6118, 0.5333, 0.4392, 0.5647, 0.5020, 0.4078, 0.5176, 0.4706, 0.4392, 0.5490, 0.5020, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.4706, 0.5961, 0.5333, 0.4392, 0.5647, 0.5020, 0.4706, 0.5804, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.4706, 0.6275, 0.5647, 0.4706, 0.5961, 0.5333, 0.4392, 0.5804, 0.5020, 0.4706, 0.5961, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5333, 0.5020, 0.6118, 0.5333, 0.4706, 0.5961, 0.5333, 0.4078, 0.5490, 0.4706, 0.4078, 0.5333, 0.4706, 0.4392, 0.5804, 0.5020, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.4706, 0.6118, 0.5333, 0.4392, 0.5804, 0.5333, 0.3765, 0.5176, 0.4392, 0.3765, 0.5176, 0.4392, 0.4706, 0.5804, 0.5020, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.4706, 0.6118, 0.5333, 0.4392, 0.5804, 0.5020, 0.3765, 0.5176, 0.4392, 0.3765, 0.5176, 0.4392, 0.4706, 0.5804, 0.5020, 0.5020, 0.6275, 0.5333, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5333, 0.5020, 0.6275, 0.5333, 0.4706, 0.5647, 0.5020, 0.4078, 0.5176, 0.4706, 0.4078, 0.5176, 0.4706, 0.4706, 0.5804, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.4706, 0.6275, 0.5333, 0.4392, 0.5647, 0.5020, 0.4078, 0.5176, 0.4392, 0.4078, 0.5333, 0.4706, 0.4706, 0.5961, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5333, 0.4392, 0.5647, 0.5020, 0.4078, 0.5176, 0.4706, 0.4078, 0.5490, 0.5020, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5333, 0.4706, 0.5804, 0.5333, 0.4078, 0.5333, 0.5020, 0.4392, 0.5647, 0.5020, 0.4706, 0.6118, 0.5333, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6431, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.4706, 0.5961, 0.5333, 0.4392, 0.5647, 0.5020, 0.4392, 0.5804, 0.5333, 0.4706, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5647, 0.5020, 0.6118, 0.5333, 0.4706, 0.5961, 0.5333, 0.4706, 0.5961, 0.5333, 0.5020, 0.6118, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.6275, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5804, 0.5647, 0.5020, 0.5804, 0.5647, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.4706, 0.5961, 0.5333, 0.4706, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.5961, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.5020, 0.6118, 0.5333, 0.4706, 0.5804, 0.5020, 0.4706, 0.5804, 0.5020, 0.4706, 0.5647, 0.5020, 0.4706, 0.5647, 0.5020, 0.4706, 0.5647, 0.5333, 0.4706, 0.5647, 0.5333, 0.4706, 0.5804, 0.5020, 0.4706, 0.5804, 0.5020, 0.4706, 0.5804, 0.5333, 0.4706, 0.5804, 0.5020, 0.4706, 0.5804, 0.5020, 0.5020, 0.5804, 0.5020, 0.4706, 0.5804, 0.5020, 0.4706, 0.5961, 0.5020, 0.4706, 0.5804, 0.5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"digit_model_quant.tflite\"\n",
    "model_path = \"digit_model_quant.tflite_int8.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input details:\n",
      "[{'name': 'input_6', 'index': 0, 'shape': array([ 1, 25, 15,  3], dtype=int32), 'shape_signature': array([-1, 25, 15,  3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0013533256715163589, -128), 'quantization_parameters': {'scales': array([0.0014], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n",
      "Output details:\n",
      "[{'name': 'Identity', 'index': 21, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.0039], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate tensors\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Print the input and output details of the model\n",
    "print()\n",
    "print(\"Input details:\")\n",
    "print(input_details)\n",
    "print()\n",
    "print(\"Output details:\")\n",
    "print(output_details)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input scale: 0.0013533256715163589\n",
      "Input zero point: -128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert features to NumPy array\n",
    "np_features = np.array(features)\n",
    "np_features = np_features.reshape(25,15,3)\n",
    "\n",
    "# If the expected input type is int8 (quantized model), rescale data\n",
    "input_type = input_details[0]['dtype']\n",
    "if input_type == np.int8:\n",
    "    input_scale, input_zero_point = input_details[0]['quantization']\n",
    "    print(\"Input scale:\", input_scale)\n",
    "    print(\"Input zero point:\", input_zero_point)\n",
    "    print()\n",
    "    np_features = (np_features / input_scale) + input_zero_point\n",
    "    np_features = np.around(np_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to NumPy array of expected type\n",
    "np_features = np_features.astype(input_type)\n",
    "\n",
    "# Add dimension to input sample (TFLite model expects (# samples, data))\n",
    "np_features = np.expand_dims(np_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input tensor out of raw features\n",
    "interpreter.set_tensor(input_details[0]['index'], np_features)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_details[0]['index'] = the index which provides the input\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output scores: [[-119  105 -128 -119 -128 -128 -122 -128 -128 -128]]\n",
      "Output scale: 0.00390625\n",
      "Output zero point: -128\n",
      "\n",
      "Inference output: [[0.0352 0.9102 0.     0.0352 0.     0.     0.0234 0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# If the output type is int8 (quantized model), rescale data\n",
    "output_type = output_details[0]['dtype']\n",
    "if output_type == np.int8:\n",
    "    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "    print(\"Raw output scores:\", output)\n",
    "    print(\"Output scale:\", output_scale)\n",
    "    print(\"Output zero point:\", output_zero_point)\n",
    "    print()\n",
    "    output = output_scale * (output.astype(np.float32) - output_zero_point)\n",
    "\n",
    "# Print the results of inference\n",
    "print(\"Inference output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference output: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# If the output type is int8 (quantized model), rescale data\n",
    "output_type = output_details[0]['dtype']\n",
    "if output_type == np.int8:\n",
    "    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "    print(\"Raw output scores:\", output)\n",
    "    print(\"Output scale:\", output_scale)\n",
    "    print(\"Output zero point:\", output_zero_point)\n",
    "    print()\n",
    "    output = output_scale * (output.astype(np.float32) - output_zero_point)\n",
    "\n",
    "# Print the results of inference\n",
    "print(\"Inference output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='/home/george/Documents/2022/tinyml/presentation/tiny-fsdl/ml/data/raw_images/fine/1_1_2affa617-0eca-431a-91a1-02d742f67213.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = Image.open(Input_dir)\n",
    "test_image = np.array(test_image, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.502 , 0.6118, 0.5333],\n",
       "        [0.502 , 0.6431, 0.5647],\n",
       "        [0.5333, 0.6431, 0.5647],\n",
       "        ...,\n",
       "        [0.502 , 0.6431, 0.5333],\n",
       "        [0.502 , 0.6431, 0.5333],\n",
       "        [0.502 , 0.6431, 0.5647]],\n",
       "\n",
       "       [[0.502 , 0.6118, 0.5333],\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        ...,\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        [0.502 , 0.6431, 0.5647],\n",
       "        [0.5333, 0.6431, 0.5647]],\n",
       "\n",
       "       [[0.4706, 0.6118, 0.5333],\n",
       "        [0.502 , 0.6275, 0.5333],\n",
       "        [0.502 , 0.6275, 0.5333],\n",
       "        ...,\n",
       "        [0.502 , 0.6275, 0.5333],\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        [0.502 , 0.6431, 0.5333]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.502 , 0.6275, 0.5647],\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        ...,\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        [0.502 , 0.6275, 0.5647],\n",
       "        [0.502 , 0.6275, 0.5647]],\n",
       "\n",
       "       [[0.502 , 0.5961, 0.5333],\n",
       "        [0.502 , 0.5961, 0.5333],\n",
       "        [0.502 , 0.5961, 0.5333],\n",
       "        ...,\n",
       "        [0.502 , 0.6118, 0.5333],\n",
       "        [0.502 , 0.6118, 0.5333],\n",
       "        [0.502 , 0.6118, 0.5333]],\n",
       "\n",
       "       [[0.4706, 0.5804, 0.502 ],\n",
       "        [0.4706, 0.5804, 0.502 ],\n",
       "        [0.4706, 0.5647, 0.502 ],\n",
       "        ...,\n",
       "        [0.4706, 0.5804, 0.502 ],\n",
       "        [0.4706, 0.5961, 0.502 ],\n",
       "        [0.4706, 0.5804, 0.502 ]]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = np.array(features).reshape(25,15,3)\n",
    "# new_feat = features.\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[126., 158., 137.],\n",
       "        [132., 164., 141.],\n",
       "        [132., 164., 141.],\n",
       "        ...,\n",
       "        [130., 163., 142.],\n",
       "        [129., 163., 139.],\n",
       "        [131., 165., 141.]],\n",
       "\n",
       "       [[123., 155., 134.],\n",
       "        [129., 161., 138.],\n",
       "        [129., 161., 138.],\n",
       "        ...,\n",
       "        [127., 160., 139.],\n",
       "        [128., 162., 138.],\n",
       "        [132., 166., 142.]],\n",
       "\n",
       "       [[123., 155., 134.],\n",
       "        [129., 161., 138.],\n",
       "        [128., 160., 137.],\n",
       "        ...,\n",
       "        [127., 160., 139.],\n",
       "        [127., 161., 137.],\n",
       "        [131., 165., 141.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[129., 160., 142.],\n",
       "        [129., 160., 142.],\n",
       "        [129., 160., 142.],\n",
       "        ...,\n",
       "        [128., 159., 141.],\n",
       "        [129., 160., 142.],\n",
       "        [129., 160., 142.]],\n",
       "\n",
       "       [[125., 154., 136.],\n",
       "        [125., 154., 136.],\n",
       "        [125., 154., 136.],\n",
       "        ...,\n",
       "        [127., 156., 138.],\n",
       "        [127., 156., 138.],\n",
       "        [127., 156., 138.]],\n",
       "\n",
       "       [[120., 147., 128.],\n",
       "        [119., 146., 129.],\n",
       "        [118., 145., 128.],\n",
       "        ...,\n",
       "        [120., 147., 130.],\n",
       "        [123., 150., 133.],\n",
       "        [120., 147., 130.]]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.reshape(test_image,[1,25,15,3])\n",
    "classes = np.argmax(model.predict(img), axis=-1)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4941, 0.6196, 0.5373],\n",
       "        [0.5176, 0.6431, 0.5529],\n",
       "        [0.5176, 0.6431, 0.5529],\n",
       "        ...,\n",
       "        [0.5098, 0.6392, 0.5569],\n",
       "        [0.5059, 0.6392, 0.5451],\n",
       "        [0.5137, 0.6471, 0.5529]],\n",
       "\n",
       "       [[0.4824, 0.6078, 0.5255],\n",
       "        [0.5059, 0.6314, 0.5412],\n",
       "        [0.5059, 0.6314, 0.5412],\n",
       "        ...,\n",
       "        [0.498 , 0.6275, 0.5451],\n",
       "        [0.502 , 0.6353, 0.5412],\n",
       "        [0.5176, 0.651 , 0.5569]],\n",
       "\n",
       "       [[0.4824, 0.6078, 0.5255],\n",
       "        [0.5059, 0.6314, 0.5412],\n",
       "        [0.502 , 0.6275, 0.5373],\n",
       "        ...,\n",
       "        [0.498 , 0.6275, 0.5451],\n",
       "        [0.498 , 0.6314, 0.5373],\n",
       "        [0.5137, 0.6471, 0.5529]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.5059, 0.6275, 0.5569],\n",
       "        [0.5059, 0.6275, 0.5569],\n",
       "        [0.5059, 0.6275, 0.5569],\n",
       "        ...,\n",
       "        [0.502 , 0.6235, 0.5529],\n",
       "        [0.5059, 0.6275, 0.5569],\n",
       "        [0.5059, 0.6275, 0.5569]],\n",
       "\n",
       "       [[0.4902, 0.6039, 0.5333],\n",
       "        [0.4902, 0.6039, 0.5333],\n",
       "        [0.4902, 0.6039, 0.5333],\n",
       "        ...,\n",
       "        [0.498 , 0.6118, 0.5412],\n",
       "        [0.498 , 0.6118, 0.5412],\n",
       "        [0.498 , 0.6118, 0.5412]],\n",
       "\n",
       "       [[0.4706, 0.5765, 0.502 ],\n",
       "        [0.4667, 0.5725, 0.5059],\n",
       "        [0.4627, 0.5686, 0.502 ],\n",
       "        ...,\n",
       "        [0.4706, 0.5765, 0.5098],\n",
       "        [0.4824, 0.5882, 0.5216],\n",
       "        [0.4706, 0.5765, 0.5098]]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.reshape(test_image,[1,25,15,3])\n",
    "classes = np.argmax(model.predict(img), axis=-1)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
